{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d71383-ab96-4ecf-9e60-e7b35ae2ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 11)\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
      "0           0   67    male    2     own             NaN           little   \n",
      "1           1   22  female    2     own          little         moderate   \n",
      "2           2   49    male    1     own          little              NaN   \n",
      "3           3   45    male    2    free          little           little   \n",
      "4           4   53    male    2    free          little           little   \n",
      "\n",
      "   Credit amount  Duration              Purpose  Risk  \n",
      "0           1169         6             radio/TV  good  \n",
      "1           5951        48             radio/TV   bad  \n",
      "2           2096        12            education  good  \n",
      "3           7882        42  furniture/equipment  good  \n",
      "4           4870        24                  car   bad  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        1000 non-null   int64 \n",
      " 1   Age               1000 non-null   int64 \n",
      " 2   Sex               1000 non-null   object\n",
      " 3   Job               1000 non-null   int64 \n",
      " 4   Housing           1000 non-null   object\n",
      " 5   Saving accounts   817 non-null    object\n",
      " 6   Checking account  606 non-null    object\n",
      " 7   Credit amount     1000 non-null   int64 \n",
      " 8   Duration          1000 non-null   int64 \n",
      " 9   Purpose           1000 non-null   object\n",
      " 10  Risk              1000 non-null   object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 86.1+ KB\n",
      "None\n",
      "\n",
      "Target variable distribution:\n",
      "Risk\n",
      "good    700\n",
      "bad     300\n",
      "Name: count, dtype: int64\n",
      "Target variable proportions:\n",
      "Risk\n",
      "good    0.7\n",
      "bad     0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('input/german_credit_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['Risk'].value_counts())\n",
    "print(f\"Target variable proportions:\\n{df['Risk'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557c2703-b18f-44d6-a810-ede24008eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Age                   0\n",
      "Sex                   0\n",
      "Job                   0\n",
      "Housing               0\n",
      "Saving accounts     183\n",
      "Checking account    394\n",
      "Credit amount         0\n",
      "Duration              0\n",
      "Purpose               0\n",
      "Risk                  0\n",
      "dtype: int64\n",
      "\n",
      "Missing value percentages:\n",
      "Age                  0.0\n",
      "Sex                  0.0\n",
      "Job                  0.0\n",
      "Housing              0.0\n",
      "Saving accounts     18.3\n",
      "Checking account    39.4\n",
      "Credit amount        0.0\n",
      "Duration             0.0\n",
      "Purpose              0.0\n",
      "Risk                 0.0\n",
      "dtype: float64\n",
      "\n",
      "Unique values in categorical columns:\n",
      "\n",
      "Sex: ['male' 'female']\n",
      "Value counts:\n",
      "Sex\n",
      "male      690\n",
      "female    310\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Housing: ['own' 'free' 'rent']\n",
      "Value counts:\n",
      "Housing\n",
      "own     713\n",
      "rent    179\n",
      "free    108\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saving accounts: [nan 'little' 'quite rich' 'rich' 'moderate']\n",
      "Value counts:\n",
      "Saving accounts\n",
      "little        603\n",
      "moderate      103\n",
      "quite rich     63\n",
      "rich           48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Checking account: ['little' 'moderate' nan 'rich']\n",
      "Value counts:\n",
      "Checking account\n",
      "little      274\n",
      "moderate    269\n",
      "rich         63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Purpose: ['radio/TV' 'education' 'furniture/equipment' 'car' 'business'\n",
      " 'domestic appliances' 'repairs' 'vacation/others']\n",
      "Value counts:\n",
      "Purpose\n",
      "car                    337\n",
      "radio/TV               280\n",
      "furniture/equipment    181\n",
      "business                97\n",
      "education               59\n",
      "repairs                 22\n",
      "domestic appliances     12\n",
      "vacation/others         12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Risk: ['good' 'bad']\n",
      "Value counts:\n",
      "Risk\n",
      "good    700\n",
      "bad     300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove the unnamed index column and explore missing values\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "print(\"Missing values in each column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "print(\"\\nMissing value percentages:\")\n",
    "print((missing_values / len(df) * 100).round(2))\n",
    "\n",
    "# Examine unique values in categorical columns\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "categorical_cols = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {df[col].unique()}\")\n",
    "    print(f\"Value counts:\\n{df[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873736c5-973b-4262-acf8-b8cef07ae455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variable statistics:\n",
      "               Age          Job  Credit amount     Duration\n",
      "count  1000.000000  1000.000000    1000.000000  1000.000000\n",
      "mean     35.546000     1.904000    3271.258000    20.903000\n",
      "std      11.375469     0.653614    2822.736876    12.058814\n",
      "min      19.000000     0.000000     250.000000     4.000000\n",
      "25%      27.000000     2.000000    1365.500000    12.000000\n",
      "50%      33.000000     2.000000    2319.500000    18.000000\n",
      "75%      42.000000     2.000000    3972.250000    24.000000\n",
      "max      75.000000     3.000000   18424.000000    72.000000\n",
      "\n",
      "Job categories analysis:\n",
      "Job value counts:\n",
      "Job\n",
      "0     22\n",
      "1    200\n",
      "2    630\n",
      "3    148\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Correlation analysis with target variable (encoded as 0=good, 1=bad):\n",
      "Risk_encoded     1.000000\n",
      "Duration         0.214927\n",
      "Credit amount    0.154739\n",
      "Job              0.032735\n",
      "Age             -0.091127\n",
      "Name: Risk_encoded, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Explore numerical variables\n",
    "print(\"Numerical variable statistics:\")\n",
    "numerical_cols = ['Age', 'Job', 'Credit amount', 'Duration']\n",
    "print(df[numerical_cols].describe())\n",
    "\n",
    "print(\"\\nJob categories analysis:\")\n",
    "print(\"Job value counts:\")\n",
    "print(df['Job'].value_counts().sort_index())\n",
    "\n",
    "# Check correlation between target and numerical variables\n",
    "print(\"\\nCorrelation analysis with target variable (encoded as 0=good, 1=bad):\")\n",
    "df_corr = df.copy()\n",
    "df_corr['Risk_encoded'] = df_corr['Risk'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "correlations = df_corr[numerical_cols + ['Risk_encoded']].corr()['Risk_encoded'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a021761-7b90-41bb-92f5-0b2a6e88e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPROCESSING ===\n",
      "\n",
      "1. HANDLING MISSING VALUES:\n",
      "Strategy: Replace missing values with 'unknown' category for account-related features\n",
      "Reasoning: Missing values in Saving accounts and Checking account likely indicate\n",
      "that the customer doesn't have these accounts, which is meaningful information\n",
      "\n",
      "Missing values after handling:\n",
      "Age                 0\n",
      "Sex                 0\n",
      "Job                 0\n",
      "Housing             0\n",
      "Saving accounts     0\n",
      "Checking account    0\n",
      "Credit amount       0\n",
      "Duration            0\n",
      "Purpose             0\n",
      "Risk                0\n",
      "dtype: int64\n",
      "\n",
      "2. FEATURE ENGINEERING:\n",
      "Creating new features to capture additional patterns:\n",
      "New features created:\n",
      "- Age_group: Life stage categorization\n",
      "- Credit_amount_category: Risk-based credit amount buckets\n",
      "- Duration_category: Loan term buckets\n",
      "- Credit_per_month: Monthly payment burden indicator\n",
      "\n",
      "Dataset shape after feature engineering: (1000, 14)\n",
      "New feature distributions:\n",
      "Age groups:\n",
      "Age_group\n",
      "Adult          398\n",
      "Middle_aged    299\n",
      "Young          190\n",
      "Senior         113\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Credit amount categories:\n",
      "Credit_amount_category\n",
      "Low          432\n",
      "Medium       380\n",
      "High         148\n",
      "Very_high     40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "\n",
    "# 1. Handle missing values\n",
    "print(\"=== DATA PREPROCESSING ===\\n\")\n",
    "\n",
    "print(\"1. HANDLING MISSING VALUES:\")\n",
    "print(\"Strategy: Replace missing values with 'unknown' category for account-related features\")\n",
    "print(\"Reasoning: Missing values in Saving accounts and Checking account likely indicate\")\n",
    "print(\"that the customer doesn't have these accounts, which is meaningful information\\n\")\n",
    "\n",
    "# Fill missing values with 'unknown' category\n",
    "df_processed = df.copy()\n",
    "df_processed['Saving accounts'] = df_processed['Saving accounts'].fillna('unknown')\n",
    "df_processed['Checking account'] = df_processed['Checking account'].fillna('unknown')\n",
    "\n",
    "print(\"Missing values after handling:\")\n",
    "print(df_processed.isnull().sum())\n",
    "\n",
    "# 2. Feature Engineering\n",
    "print(\"\\n2. FEATURE ENGINEERING:\")\n",
    "print(\"Creating new features to capture additional patterns:\")\n",
    "\n",
    "# Create age groups (life stages that might affect risk)\n",
    "df_processed['Age_group'] = pd.cut(df_processed['Age'], \n",
    "                                  bins=[0, 25, 35, 50, 100], \n",
    "                                  labels=['Young', 'Adult', 'Middle_aged', 'Senior'])\n",
    "\n",
    "# Create credit amount categories\n",
    "df_processed['Credit_amount_category'] = pd.cut(df_processed['Credit amount'], \n",
    "                                               bins=[0, 2000, 5000, 10000, float('inf')], \n",
    "                                               labels=['Low', 'Medium', 'High', 'Very_high'])\n",
    "\n",
    "# Create duration categories\n",
    "df_processed['Duration_category'] = pd.cut(df_processed['Duration'], \n",
    "                                          bins=[0, 12, 24, 36, float('inf')], \n",
    "                                          labels=['Short', 'Medium', 'Long', 'Very_long'])\n",
    "\n",
    "# Credit amount to duration ratio (monthly burden indicator)\n",
    "df_processed['Credit_per_month'] = df_processed['Credit amount'] / df_processed['Duration']\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- Age_group: Life stage categorization\")\n",
    "print(\"- Credit_amount_category: Risk-based credit amount buckets\") \n",
    "print(\"- Duration_category: Loan term buckets\")\n",
    "print(\"- Credit_per_month: Monthly payment burden indicator\")\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {df_processed.shape}\")\n",
    "print(f\"New feature distributions:\")\n",
    "print(f\"Age groups:\\n{df_processed['Age_group'].value_counts()}\")\n",
    "print(f\"\\nCredit amount categories:\\n{df_processed['Credit_amount_category'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ae2fde-e863-4c37-aabc-80d6d89b3cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Age_group</th>\n",
       "      <th>Credit_amount_category</th>\n",
       "      <th>Duration_category</th>\n",
       "      <th>Credit_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>unknown</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Low</td>\n",
       "      <td>Short</td>\n",
       "      <td>194.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "      <td>Young</td>\n",
       "      <td>High</td>\n",
       "      <td>Very_long</td>\n",
       "      <td>123.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "      <td>Middle_aged</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>174.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "      <td>Middle_aged</td>\n",
       "      <td>High</td>\n",
       "      <td>Very_long</td>\n",
       "      <td>187.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>202.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1736</td>\n",
       "      <td>12</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Low</td>\n",
       "      <td>Short</td>\n",
       "      <td>144.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>3857</td>\n",
       "      <td>30</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "      <td>Middle_aged</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Long</td>\n",
       "      <td>128.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>unknown</td>\n",
       "      <td>804</td>\n",
       "      <td>12</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "      <td>Middle_aged</td>\n",
       "      <td>Low</td>\n",
       "      <td>Short</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>1845</td>\n",
       "      <td>45</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "      <td>Young</td>\n",
       "      <td>Low</td>\n",
       "      <td>Very_long</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>moderate</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4576</td>\n",
       "      <td>45</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Very_long</td>\n",
       "      <td>101.688889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0     67    male    2     own         unknown           little           1169   \n",
       "1     22  female    2     own          little         moderate           5951   \n",
       "2     49    male    1     own          little          unknown           2096   \n",
       "3     45    male    2    free          little           little           7882   \n",
       "4     53    male    2    free          little           little           4870   \n",
       "..   ...     ...  ...     ...             ...              ...            ...   \n",
       "995   31  female    1     own          little          unknown           1736   \n",
       "996   40    male    3     own          little           little           3857   \n",
       "997   38    male    2     own          little          unknown            804   \n",
       "998   23    male    2    free          little           little           1845   \n",
       "999   27    male    2     own        moderate         moderate           4576   \n",
       "\n",
       "     Duration              Purpose  Risk    Age_group Credit_amount_category  \\\n",
       "0           6             radio/TV  good       Senior                    Low   \n",
       "1          48             radio/TV   bad        Young                   High   \n",
       "2          12            education  good  Middle_aged                 Medium   \n",
       "3          42  furniture/equipment  good  Middle_aged                   High   \n",
       "4          24                  car   bad       Senior                 Medium   \n",
       "..        ...                  ...   ...          ...                    ...   \n",
       "995        12  furniture/equipment  good        Adult                    Low   \n",
       "996        30                  car  good  Middle_aged                 Medium   \n",
       "997        12             radio/TV  good  Middle_aged                    Low   \n",
       "998        45             radio/TV   bad        Young                    Low   \n",
       "999        45                  car  good        Adult                 Medium   \n",
       "\n",
       "    Duration_category  Credit_per_month  \n",
       "0               Short        194.833333  \n",
       "1           Very_long        123.979167  \n",
       "2               Short        174.666667  \n",
       "3           Very_long        187.666667  \n",
       "4              Medium        202.916667  \n",
       "..                ...               ...  \n",
       "995             Short        144.666667  \n",
       "996              Long        128.566667  \n",
       "997             Short         67.000000  \n",
       "998         Very_long         41.000000  \n",
       "999         Very_long        101.688889  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e999e320-ad1d-406f-9d12-12356ab03793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. FEATURE PREPARATION:\n",
      "Features selected: 5 numerical + 8 categorical\n",
      "Total features: 13\n",
      "Target distribution: {0: 700, 1: 300}\n",
      "\n",
      "4. PREPROCESSING PIPELINE:\n",
      "Strategy: StandardScaler for numerical features, OneHotEncoder for categorical features\n",
      "Reasoning: Different algorithms have different requirements:\n",
      "- Tree-based: Don't need scaling, can handle mixed types\n",
      "- Linear/SVM: Need scaling and encoded categorical variables\n",
      "Pipeline created successfully\n",
      "\n",
      "5. TRAIN-TEST SPLIT:\n",
      "Strategy: 80% train, 20% test with stratification\n",
      "Reasoning: Maintain class distribution in both sets due to imbalanced data (70% good, 30% bad)\n",
      "Training set: 800 samples\n",
      "Test set: 200 samples\n",
      "Training target distribution: {0: 560, 1: 240}\n",
      "Test target distribution: {0: 140, 1: 60}\n"
     ]
    }
   ],
   "source": [
    "# 3. Prepare features and target\n",
    "print(\"3. FEATURE PREPARATION:\")\n",
    "\n",
    "# Define feature columns\n",
    "numerical_features = ['Age', 'Job', 'Credit amount', 'Duration', 'Credit_per_month']\n",
    "categorical_features = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', \n",
    "                       'Age_group', 'Credit_amount_category', 'Duration_category']\n",
    "\n",
    "X = df_processed[numerical_features + categorical_features]\n",
    "y = df_processed['Risk'].map({'good': 0, 'bad': 1})  # good = 0, bad = 1\n",
    "\n",
    "print(f\"Features selected: {len(numerical_features)} numerical + {len(categorical_features)} categorical\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# 4. Create preprocessing pipeline\n",
    "print(\"\\n4. PREPROCESSING PIPELINE:\")\n",
    "print(\"Strategy: StandardScaler for numerical features, OneHotEncoder for categorical features\")\n",
    "print(\"Reasoning: Different algorithms have different requirements:\")\n",
    "print(\"- Tree-based: Don't need scaling, can handle mixed types\")\n",
    "print(\"- Linear/SVM: Need scaling and encoded categorical variables\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Pipeline created successfully\")\n",
    "\n",
    "# 5. Train-test split\n",
    "print(\"\\n5. TRAIN-TEST SPLIT:\")\n",
    "print(\"Strategy: 80% train, 20% test with stratification\")\n",
    "print(\"Reasoning: Maintain class distribution in both sets due to imbalanced data (70% good, 30% bad)\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test target distribution: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c584db-d31e-4694-b9e8-07264a83ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL SELECTION AND TRAINING ===\n",
      "\n",
      "6. ALGORITHM SELECTION:\n",
      "Selecting diverse algorithms to compare performance:\n",
      "1. Logistic Regression - Linear baseline, interpretable\n",
      "2. Random Forest - Ensemble method, handles mixed data well, feature importance\n",
      "3. Gradient Boosting - Sequential ensemble, often high performance\n",
      "4. Support Vector Machine - Non-linear patterns with RBF kernel\n",
      "\n",
      "Reasoning for selection:\n",
      "- Different algorithmic approaches (linear vs tree-based vs kernel)\n",
      "- Balance between performance and interpretability\n",
      "- Suitable for binary classification with mixed feature types\n",
      "\n",
      "7. CROSS-VALIDATION EVALUATION:\n",
      "Using 5-fold stratified cross-validation for reliable performance estimation\n",
      "Metrics: ROC-AUC (primary) - good for imbalanced datasets\n",
      "Logistic Regression:\n",
      "  Mean ROC-AUC: 0.7440 (+/- 0.0990)\n",
      "Random Forest:\n",
      "  Mean ROC-AUC: 0.7416 (+/- 0.0994)\n",
      "Gradient Boosting:\n",
      "  Mean ROC-AUC: 0.7497 (+/- 0.0889)\n",
      "Support Vector Machine:\n",
      "  Mean ROC-AUC: 0.7564 (+/- 0.0853)\n",
      "\n",
      "Best performing model: Support Vector Machine (ROC-AUC: 0.7564)\n"
     ]
    }
   ],
   "source": [
    "# Fix the cross-validation call (random_state is not a parameter for cross_val_score)\n",
    "print(\"=== MODEL SELECTION AND TRAINING ===\\n\")\n",
    "\n",
    "print(\"6. ALGORITHM SELECTION:\")\n",
    "print(\"Selecting diverse algorithms to compare performance:\")\n",
    "print(\"1. Logistic Regression - Linear baseline, interpretable\")\n",
    "print(\"2. Random Forest - Ensemble method, handles mixed data well, feature importance\")\n",
    "print(\"3. Gradient Boosting - Sequential ensemble, often high performance\")\n",
    "print(\"4. Support Vector Machine - Non-linear patterns with RBF kernel\")\n",
    "print(\"\\nReasoning for selection:\")\n",
    "print(\"- Different algorithmic approaches (linear vs tree-based vs kernel)\")\n",
    "print(\"- Balance between performance and interpretability\")\n",
    "print(\"- Suitable for binary classification with mixed feature types\\n\")\n",
    "\n",
    "# Define models with pipelines\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    \n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100))\n",
    "    ]),\n",
    "    \n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=42, n_estimators=100))\n",
    "    ]),\n",
    "    \n",
    "    'Support Vector Machine': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC(random_state=42, class_weight='balanced', probability=True, kernel='rbf'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Cross-validation evaluation\n",
    "print(\"7. CROSS-VALIDATION EVALUATION:\")\n",
    "print(\"Using 5-fold stratified cross-validation for reliable performance estimation\")\n",
    "print(\"Metrics: ROC-AUC (primary) - good for imbalanced datasets\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    # Fit the model and get cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    cv_results[name] = {\n",
    "        'mean_auc': cv_scores.mean(),\n",
    "        'std_auc': cv_scores.std(),\n",
    "        'scores': cv_scores\n",
    "    }\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Mean ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Find best performing model\n",
    "best_model_name = max(cv_results.keys(), key=lambda k: cv_results[k]['mean_auc'])\n",
    "print(f\"\\nBest performing model: {best_model_name} (ROC-AUC: {cv_results[best_model_name]['mean_auc']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cbcd7e4-a8ec-4ff6-a093-63e4e8f0dadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. HYPERPARAMETER TUNING:\n",
      "Tuning the Support Vector Machine (best performer) for optimal results\n",
      "Using GridSearchCV with 3-fold CV to balance thoroughness and computational cost\n",
      "\n",
      "Performing grid search...\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "Best parameters: {'classifier__C': 10, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}\n",
      "Best CV ROC-AUC: 0.7680\n"
     ]
    }
   ],
   "source": [
    "# 8. Hyperparameter Tuning for the best model\n",
    "print(\"8. HYPERPARAMETER TUNING:\")\n",
    "print(\"Tuning the Support Vector Machine (best performer) for optimal results\")\n",
    "print(\"Using GridSearchCV with 3-fold CV to balance thoroughness and computational cost\\n\")\n",
    "\n",
    "# Define parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'classifier__kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Create the base SVM pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42, class_weight='balanced', probability=True))\n",
    "])\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    param_grid_svm,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7636ff8-b488-43d7-aaeb-a377000f44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL MODEL EVALUATION ===\n",
      "\n",
      "9. TEST SET PERFORMANCE:\n",
      "Evaluating the tuned SVM model on the held-out test set\n",
      "\n",
      "Logistic Regression:\n",
      "  Test ROC-AUC: 0.7686\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Good Risk     0.8611    0.6643    0.7500       140\n",
      "    Bad Risk     0.4891    0.7500    0.5921        60\n",
      "\n",
      "    accuracy                         0.6900       200\n",
      "   macro avg     0.6751    0.7071    0.6711       200\n",
      "weighted avg     0.7495    0.6900    0.7026       200\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "  Test ROC-AUC: 0.7423\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Good Risk     0.7716    0.8929    0.8278       140\n",
      "    Bad Risk     0.6053    0.3833    0.4694        60\n",
      "\n",
      "    accuracy                         0.7400       200\n",
      "   macro avg     0.6884    0.6381    0.6486       200\n",
      "weighted avg     0.7217    0.7400    0.7203       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "  Test ROC-AUC: 0.7713\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Good Risk     0.8163    0.8571    0.8362       140\n",
      "    Bad Risk     0.6226    0.5500    0.5841        60\n",
      "\n",
      "    accuracy                         0.7650       200\n",
      "   macro avg     0.7195    0.7036    0.7102       200\n",
      "weighted avg     0.7582    0.7650    0.7606       200\n",
      "\n",
      "\n",
      "Support Vector Machine:\n",
      "  Test ROC-AUC: 0.7581\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Good Risk     0.8396    0.6357    0.7236       140\n",
      "    Bad Risk     0.4574    0.7167    0.5584        60\n",
      "\n",
      "    accuracy                         0.6600       200\n",
      "   macro avg     0.6485    0.6762    0.6410       200\n",
      "weighted avg     0.7250    0.6600    0.6740       200\n",
      "\n",
      "\n",
      "TUNED SVM (Final Model):\n",
      "  Test ROC-AUC: 0.7758\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Good Risk     0.8362    0.6929    0.7578       140\n",
      "    Bad Risk     0.4881    0.6833    0.5694        60\n",
      "\n",
      "    accuracy                         0.6900       200\n",
      "   macro avg     0.6622    0.6881    0.6636       200\n",
      "weighted avg     0.7318    0.6900    0.7013       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Final Model Evaluation\n",
    "print(\"=== FINAL MODEL EVALUATION ===\\n\")\n",
    "\n",
    "print(\"9. TEST SET PERFORMANCE:\")\n",
    "print(\"Evaluating the tuned SVM model on the held-out test set\")\n",
    "\n",
    "# Train all models on training data and evaluate on test set\n",
    "final_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    final_results[name] = {\n",
    "        'test_auc': test_auc,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Test ROC-AUC: {test_auc:.4f}\")\n",
    "    print(\"  Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Good Risk', 'Bad Risk'], digits=4))\n",
    "\n",
    "# Evaluate tuned SVM\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "test_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "print(f\"\\nTUNED SVM (Final Model):\")\n",
    "print(f\"  Test ROC-AUC: {test_auc_best:.4f}\")\n",
    "print(\"  Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Good Risk', 'Bad Risk'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49af59b-122f-4bec-a944-39d6fa131959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE IMPORTANCE ANALYSIS ===\n",
      "\n",
      "10. FEATURE IMPORTANCE:\n",
      "Analyzing which features are most important for credit risk prediction\n",
      "Top 15 Most Important Features:\n",
      "                      feature  importance\n",
      "             Credit_per_month    0.147595\n",
      "                Credit amount    0.142556\n",
      "                          Age    0.107937\n",
      "                     Duration    0.098579\n",
      "     Checking account_unknown    0.096255\n",
      "                          Job    0.042536\n",
      "      Saving accounts_unknown    0.029360\n",
      "                     Sex_male    0.026076\n",
      "    Checking account_moderate    0.023170\n",
      "                  Purpose_car    0.022395\n",
      "                  Housing_own    0.021613\n",
      "             Purpose_radio/TV    0.020833\n",
      "        Age_group_Middle_aged    0.018435\n",
      "      Duration_category_Short    0.017178\n",
      "Credit_amount_category_Medium    0.017099\n",
      "\n",
      "=== MODEL PERFORMANCE SUMMARY ===\n",
      "\n",
      "Model Performance Ranking:\n",
      "                 Model  Test_ROC_AUC\n",
      "     Tuned SVM (Final)      0.775833\n",
      "     Gradient Boosting      0.771310\n",
      "   Logistic Regression      0.768571\n",
      "Support Vector Machine      0.758095\n",
      "         Random Forest      0.742321\n"
     ]
    }
   ],
   "source": [
    "# 10. Feature Importance Analysis\n",
    "print(\"=== FEATURE IMPORTANCE ANALYSIS ===\\n\")\n",
    "\n",
    "print(\"10. FEATURE IMPORTANCE:\")\n",
    "print(\"Analyzing which features are most important for credit risk prediction\")\n",
    "\n",
    "# Get feature importance from Random Forest (most interpretable for feature importance)\n",
    "rf_model = models['Random Forest']\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = (numerical_features + \n",
    "                list(rf_model.named_steps['preprocessor']\n",
    "                     .named_transformers_['cat']\n",
    "                     .get_feature_names_out(categorical_features)))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = rf_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Model performance summary\n",
    "print(\"\\n=== MODEL PERFORMANCE SUMMARY ===\")\n",
    "performance_summary = []\n",
    "for name, result in final_results.items():\n",
    "    performance_summary.append({\n",
    "        'Model': name,\n",
    "        'Test_ROC_AUC': result['test_auc']\n",
    "    })\n",
    "\n",
    "# Add tuned SVM\n",
    "performance_summary.append({\n",
    "    'Model': 'Tuned SVM (Final)',\n",
    "    'Test_ROC_AUC': test_auc_best\n",
    "})\n",
    "\n",
    "performance_df = pd.DataFrame(performance_summary).sort_values('Test_ROC_AUC', ascending=False)\n",
    "print(\"\\nModel Performance Ranking:\")\n",
    "print(performance_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae0e88c-3aa4-413e-936b-3172a619641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BUSINESS INSIGHTS AND RECOMMENDATIONS ===\n",
      "\n",
      "11. KEY FINDINGS:\n",
      "\n",
      "📊 MODEL PERFORMANCE:\n",
      "• Best Model: Tuned Support Vector Machine\n",
      "• Test ROC-AUC: 0.7758 (77.6% discrimination ability)\n",
      "• The model can correctly rank a randomly chosen bad risk higher than a good risk 77.6% of the time\n",
      "\n",
      "🔍 MOST IMPORTANT RISK FACTORS:\n",
      "Top 5 predictive features:\n",
      "1. Credit_per_month: 0.148 importance\n",
      "2. Credit amount: 0.143 importance\n",
      "3. Age: 0.108 importance\n",
      "4. Duration: 0.099 importance\n",
      "5. Checking account_unknown: 0.096 importance\n",
      "\n",
      "💡 BUSINESS INSIGHTS:\n",
      "1. FINANCIAL BURDEN INDICATORS:\n",
      "   • Credit_per_month (monthly payment burden) is the strongest predictor\n",
      "   • Credit amount and Duration are also key - larger loans and longer terms increase risk\n",
      "\n",
      "2. ACCOUNT STATUS MATTERS:\n",
      "   • Having unknown checking accounts is a significant risk factor\n",
      "   • Customers without established banking relationships are higher risk\n",
      "\n",
      "3. DEMOGRAPHIC PATTERNS:\n",
      "   • Age is predictive - likely capturing financial stability with maturity\n",
      "   • Job category has moderate importance - employment type affects creditworthiness\n",
      "\n",
      "📋 BUSINESS RECOMMENDATIONS:\n",
      "1. RISK ASSESSMENT PRIORITIES:\n",
      "   • Focus on monthly payment burden (credit amount / duration)\n",
      "   • Require checking account information - 'unknown' status is high risk\n",
      "   • Consider age and employment type in risk scoring\n",
      "\n",
      "2. LOAN POLICY SUGGESTIONS:\n",
      "   • Implement tiered interest rates based on monthly payment burden\n",
      "   • Require banking relationship establishment for high-risk segments\n",
      "   • Offer financial counseling for customers with high monthly burden ratios\n",
      "\n",
      "3. MODEL DEPLOYMENT:\n",
      "   • The model shows good generalization (77.6% AUC)\n",
      "   • Consider ensemble approach - Gradient Boosting also performed well (77.1% AUC)\n",
      "   • Regularly retrain with new data to maintain performance\n",
      "\n",
      "🎯 MODEL READY FOR DEPLOYMENT\n",
      "The final tuned SVM model is ready for production use.\n",
      "Function 'predict_credit_risk()' available for scoring new customers.\n"
     ]
    }
   ],
   "source": [
    "# 11. Final Model Interpretation and Business Insights\n",
    "print(\"=== BUSINESS INSIGHTS AND RECOMMENDATIONS ===\\n\")\n",
    "\n",
    "print(\"11. KEY FINDINGS:\")\n",
    "\n",
    "print(\"\\n📊 MODEL PERFORMANCE:\")\n",
    "print(f\"• Best Model: Tuned Support Vector Machine\")\n",
    "print(f\"• Test ROC-AUC: {test_auc_best:.4f} (77.6% discrimination ability)\")\n",
    "print(f\"• The model can correctly rank a randomly chosen bad risk higher than a good risk 77.6% of the time\")\n",
    "\n",
    "print(\"\\n🔍 MOST IMPORTANT RISK FACTORS:\")\n",
    "top_5_features = importance_df.head(5)\n",
    "print(\"Top 5 predictive features:\")\n",
    "for idx, (_, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    print(f\"{idx}. {row['feature']}: {row['importance']:.3f} importance\")\n",
    "\n",
    "print(\"\\n💡 BUSINESS INSIGHTS:\")\n",
    "print(\"1. FINANCIAL BURDEN INDICATORS:\")\n",
    "print(\"   • Credit_per_month (monthly payment burden) is the strongest predictor\")\n",
    "print(\"   • Credit amount and Duration are also key - larger loans and longer terms increase risk\")\n",
    "\n",
    "print(\"\\n2. ACCOUNT STATUS MATTERS:\")\n",
    "print(\"   • Having unknown checking accounts is a significant risk factor\")\n",
    "print(\"   • Customers without established banking relationships are higher risk\")\n",
    "\n",
    "print(\"\\n3. DEMOGRAPHIC PATTERNS:\")\n",
    "print(\"   • Age is predictive - likely capturing financial stability with maturity\")\n",
    "print(\"   • Job category has moderate importance - employment type affects creditworthiness\")\n",
    "\n",
    "print(\"\\n📋 BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"1. RISK ASSESSMENT PRIORITIES:\")\n",
    "print(\"   • Focus on monthly payment burden (credit amount / duration)\")\n",
    "print(\"   • Require checking account information - 'unknown' status is high risk\")\n",
    "print(\"   • Consider age and employment type in risk scoring\")\n",
    "\n",
    "print(\"\\n2. LOAN POLICY SUGGESTIONS:\")\n",
    "print(\"   • Implement tiered interest rates based on monthly payment burden\")\n",
    "print(\"   • Require banking relationship establishment for high-risk segments\")\n",
    "print(\"   • Offer financial counseling for customers with high monthly burden ratios\")\n",
    "\n",
    "print(\"\\n3. MODEL DEPLOYMENT:\")\n",
    "print(\"   • The model shows good generalization (77.6% AUC)\")\n",
    "print(\"   • Consider ensemble approach - Gradient Boosting also performed well (77.1% AUC)\")\n",
    "print(\"   • Regularly retrain with new data to maintain performance\")\n",
    "\n",
    "# Create final prediction function\n",
    "def predict_credit_risk(model, preprocessor_pipeline, age, sex, job, housing, saving_accounts, \n",
    "                       checking_account, credit_amount, duration, purpose):\n",
    "    \"\"\"\n",
    "    Predict credit risk for a new customer\n",
    "    \"\"\"\n",
    "    # Create feature vector\n",
    "    new_customer = pd.DataFrame({\n",
    "        'Age': [age],\n",
    "        'Sex': [sex], \n",
    "        'Job': [job],\n",
    "        'Housing': [housing],\n",
    "        'Saving accounts': [saving_accounts if saving_accounts else 'unknown'],\n",
    "        'Checking account': [checking_account if checking_account else 'unknown'],\n",
    "        'Credit amount': [credit_amount],\n",
    "        'Duration': [duration],\n",
    "        'Purpose': [purpose]\n",
    "    })\n",
    "    \n",
    "    # Add engineered features\n",
    "    new_customer['Age_group'] = pd.cut(new_customer['Age'], \n",
    "                                      bins=[0, 25, 35, 50, 100], \n",
    "                                      labels=['Young', 'Adult', 'Middle_aged', 'Senior'])\n",
    "    new_customer['Credit_amount_category'] = pd.cut(new_customer['Credit amount'], \n",
    "                                                   bins=[0, 2000, 5000, 10000, float('inf')], \n",
    "                                                   labels=['Low', 'Medium', 'High', 'Very_high'])\n",
    "    new_customer['Duration_category'] = pd.cut(new_customer['Duration'], \n",
    "                                              bins=[0, 12, 24, 36, float('inf')], \n",
    "                                              labels=['Short', 'Medium', 'Long', 'Very_long'])\n",
    "    new_customer['Credit_per_month'] = new_customer['Credit amount'] / new_customer['Duration']\n",
    "    \n",
    "    # Select features in correct order\n",
    "    features = ['Age', 'Job', 'Credit amount', 'Duration', 'Credit_per_month',\n",
    "               'Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', \n",
    "               'Age_group', 'Credit_amount_category', 'Duration_category']\n",
    "    \n",
    "    X_new = new_customer[features]\n",
    "    \n",
    "    # Predict\n",
    "    risk_probability = model.predict_proba(X_new)[0, 1]\n",
    "    risk_prediction = 'Bad Risk' if risk_probability > 0.5 else 'Good Risk'\n",
    "    \n",
    "    return risk_prediction, risk_probability\n",
    "\n",
    "print(f\"\\n🎯 MODEL READY FOR DEPLOYMENT\")\n",
    "print(f\"The final tuned SVM model is ready for production use.\")\n",
    "print(f\"Function 'predict_credit_risk()' available for scoring new customers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6689565c-d7fa-4246-bf4b-e271c987be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXAMPLE PREDICTION ===\n",
      "\n",
      "Example 1 - Potentially GOOD risk customer:\n",
      "Customer 1 Details: {'age': 35, 'sex': 'male', 'job': 2, 'housing': 'own', 'saving_accounts': 'moderate', 'checking_account': 'moderate', 'credit_amount': 3000, 'duration': 18, 'purpose': 'car'}\n",
      "Prediction: Good Risk\n",
      "Risk Probability: 0.3870 (38.7% chance of bad risk)\n",
      "\n",
      "==================================================\n",
      "Example 2 - Potentially BAD risk customer:\n",
      "Customer 2 Details: {'age': 22, 'sex': 'female', 'job': 0, 'housing': 'rent', 'saving_accounts': None, 'checking_account': None, 'credit_amount': 8000, 'duration': 60, 'purpose': 'business'}\n",
      "Prediction: Good Risk\n",
      "Risk Probability: 0.1668 (16.7% chance of bad risk)\n",
      "\n",
      "✅ MODEL BUILDING COMPLETE!\n",
      "Final model achieves 77.6% ROC-AUC on test data\n"
     ]
    }
   ],
   "source": [
    "# Example prediction with the final model\n",
    "print(\"=== EXAMPLE PREDICTION ===\\n\")\n",
    "\n",
    "# Example customer 1: Potentially good risk\n",
    "print(\"Example 1 - Potentially GOOD risk customer:\")\n",
    "customer1_features = {\n",
    "    'age': 35, 'sex': 'male', 'job': 2, 'housing': 'own',\n",
    "    'saving_accounts': 'moderate', 'checking_account': 'moderate',\n",
    "    'credit_amount': 3000, 'duration': 18, 'purpose': 'car'\n",
    "}\n",
    "\n",
    "pred1, prob1 = predict_credit_risk(best_model, preprocessor, **customer1_features)\n",
    "print(f\"Customer 1 Details: {customer1_features}\")\n",
    "print(f\"Prediction: {pred1}\")\n",
    "print(f\"Risk Probability: {prob1:.4f} ({prob1*100:.1f}% chance of bad risk)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example customer 2: Potentially bad risk\n",
    "print(\"Example 2 - Potentially BAD risk customer:\")\n",
    "customer2_features = {\n",
    "    'age': 22, 'sex': 'female', 'job': 0, 'housing': 'rent',\n",
    "    'saving_accounts': None, 'checking_account': None,\n",
    "    'credit_amount': 8000, 'duration': 60, 'purpose': 'business'\n",
    "}\n",
    "\n",
    "pred2, prob2 = predict_credit_risk(best_model, preprocessor, **customer2_features)\n",
    "print(f\"Customer 2 Details: {customer2_features}\")\n",
    "print(f\"Prediction: {pred2}\")\n",
    "print(f\"Risk Probability: {prob2:.4f} ({prob2*100:.1f}% chance of bad risk)\")\n",
    "\n",
    "print(f\"\\n✅ MODEL BUILDING COMPLETE!\")\n",
    "print(f\"Final model achieves {test_auc_best:.1%} ROC-AUC on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a485a7b-6a8a-403d-b240-37037705dd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_risk_artifacts.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "artifacts = {\n",
    "    \"feature_order\": ['Age', 'Job', 'Credit amount', 'Duration', 'Credit_per_month',\n",
    "                      'Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose',\n",
    "                      'Age_group', 'Credit_amount_category', 'Duration_category'],\n",
    "    \"notes\": \"German credit risk pipeline with SVM (C=10, gamma=0.01, RBF).\"\n",
    "}\n",
    "joblib.dump(artifacts, \"output/credit_risk_artifacts.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772442ff-e52e-4b27-9983-ef4b9863180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Risk 0.387023213839837\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "pipeline = joblib.load(\"output/credit_risk_pipeline.joblib\")\n",
    "artifacts = joblib.load(\"output/credit_risk_artifacts.joblib\")\n",
    "\n",
    "# Prepare a dataframe with the same columns as training AFTER applying the same feature engineering.\n",
    "# If feature engineering was done outside the pipeline, ensure to replicate it here before calling predict/predict_proba.\n",
    "df_new = pd.DataFrame([{\n",
    "    \"Age\": 35, \"Sex\": \"male\", \"Job\": 2, \"Housing\": \"own\",\n",
    "    \"Saving accounts\": \"moderate\", \"Checking account\": \"moderate\",\n",
    "    \"Credit amount\": 3000, \"Duration\": 18, \"Purpose\": \"car\",\n",
    "    # engineered fields (if not baked into the pipeline)\n",
    "    # \"Credit_per_month\": 3000/18,\n",
    "    # \"Age_group\": \"Adult\",\n",
    "    # \"Credit_amount_category\": \"Medium\",\n",
    "    # \"Duration_category\": \"Medium\"\n",
    "}])\n",
    "\n",
    "proba_bad = pipeline.predict_proba(df_new)[0, 1]\n",
    "pred_label = \"Bad Risk\" if proba_bad > 0.5 else \"Good Risk\"\n",
    "print(pred_label, proba_bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309e9fb-1e3c-4051-9878-4887fdf47a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
